{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d5756234",
      "metadata": {
        "id": "d5756234"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torchvision.transforms as transforms\n",
        "import numpy as np\n",
        "\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets\n",
        "from resnet import ResNet20, ResNet, Bottleneck\n",
        "from datetime import datetime\n",
        "from tqdm.notebook import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f9b6b9a0",
      "metadata": {
        "id": "f9b6b9a0"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c8050600",
      "metadata": {
        "id": "c8050600"
      },
      "outputs": [],
      "source": [
        "hyperparameters = {\n",
        "    'epochs': 300,\n",
        "    'lr': 0.1,\n",
        "    'lr_min': 1e-6,\n",
        "    'momentum': 0.9,\n",
        "    'weight_decay': 5e-4,\n",
        "    'batch_size': 391,\n",
        "    'sparsity_type': \"feather\",\n",
        "    'dataset': 'cifar100',\n",
        "    'model_type': 'rn50',\n",
        "    'lr_decay': \"cosine\",\n",
        "    'T_max': 280,\n",
        "    'final_rate': 0.9\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "64de9b57",
      "metadata": {
        "id": "64de9b57"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "\n",
        "class Feather:\n",
        "    def __init__(self, gth, theta):\n",
        "        self.gth = gth\n",
        "        self.theta = theta\n",
        "\n",
        "    def forward(self, w):\n",
        "        return Feather_aux.apply(w, self.gth, self.theta)\n",
        "\n",
        "class Feather_aux(torch.autograd.Function):\n",
        "    @staticmethod\n",
        "    def forward(ctx, w, gth, theta):\n",
        "        ctx.aux = torch.where(torch.abs(w) > gth, 1.0, theta)\n",
        "        p = 3\n",
        "        diff = torch.abs(w)**p - gth**p\n",
        "        w_masked = torch.where(diff > 0, torch.sign(w)*(diff)**(1/p), 0.0)\n",
        "        return w_masked\n",
        "\n",
        "    @staticmethod\n",
        "    def backward(ctx, g):\n",
        "        g = ctx.aux * g\n",
        "        return g, None, None\n",
        "\n",
        "class SparseConv(nn.Module):\n",
        "    def __init__(self, conv, feather):\n",
        "        super(SparseConv, self).__init__()\n",
        "        self.conv = conv\n",
        "        self.feather = feather\n",
        "\n",
        "    def forward(self, x):\n",
        "        w = self.conv.weight\n",
        "        b = self.conv.bias\n",
        "        stride = self.conv.stride\n",
        "        padding = self.conv.padding\n",
        "        groups = self.conv.groups\n",
        "\n",
        "        if self.feather.gth > 0:\n",
        "            w = self.feather.forward(w)\n",
        "\n",
        "        out = F.conv2d(x, w, bias=b, padding=padding, stride=stride, groups=groups)\n",
        "        return out\n",
        "\n",
        "\n",
        "class SparseFc(nn.Module):\n",
        "    def __init__(self, fc, feather):\n",
        "        super(SparseFc, self).__init__()\n",
        "        self.fc = fc\n",
        "        self.feather = feather\n",
        "\n",
        "    def forward(self, x):\n",
        "        w = self.fc.weight\n",
        "        b = self.fc.bias\n",
        "\n",
        "        if self.feather.gth > 0:\n",
        "            w = self.feather.forward(w)\n",
        "\n",
        "        out = F.linear(x, w, bias=b)\n",
        "        return out\n",
        "\n",
        "def iter_sparsify(m, feather, pthres=0):\n",
        "    for name, child in m.named_children():\n",
        "        iter_sparsify(child, feather, pthres)\n",
        "\n",
        "        if isinstance(child, nn.Conv2d):\n",
        "            nw = (child.in_channels * child.out_channels * child.kernel_size[0] * child.kernel_size[1]) / child.groups\n",
        "            if nw >= pthres:\n",
        "                slayer = SparseConv(child, feather)\n",
        "                m.__setattr__(name, slayer)\n",
        "\n",
        "        if isinstance(child, nn.Linear):\n",
        "            nw = child.in_features * child.out_features\n",
        "            if nw >= pthres:\n",
        "                slayer = SparseFc(child, feather)\n",
        "                m.__setattr__(name, slayer)\n",
        "\n",
        "\n",
        "def iter_desparsify(m, feather):\n",
        "    for name, child in m.named_children():\n",
        "        iter_desparsify(child, feather)\n",
        "\n",
        "        if isinstance(child, SparseConv):\n",
        "            conv = child.conv\n",
        "            w = conv.weight.data\n",
        "            nw = feather.forward(w)\n",
        "            conv.weight.data = nw\n",
        "            m.__setattr__(name, conv)\n",
        "\n",
        "        if isinstance(child, SparseFc):\n",
        "            fc = child.fc\n",
        "            w = fc.weight.data\n",
        "            nw = feather.forward(w)\n",
        "            fc.weight.data = nw\n",
        "            m.__setattr__(name, fc)\n",
        "\n",
        "def get_params(model):\n",
        "    bn_ids =[]\n",
        "    modules = list(model.named_modules())\n",
        "    for n, layer in modules:\n",
        "        if isinstance(layer, torch.nn.modules.batchnorm.BatchNorm2d):\n",
        "            bn_ids.append(id(layer.weight))\n",
        "            bn_ids.append(id(layer.bias))\n",
        "\n",
        "    params, params_nowd = [], []\n",
        "    for name, p in model.named_parameters():\n",
        "        if id(p) in bn_ids or 'bias' in name:\n",
        "            params_nowd += [p]\n",
        "        else:\n",
        "            params += [p]\n",
        "    return params, params_nowd\n",
        "\n",
        "def get_prunable_weights_cnt(model):\n",
        "    prunable_weights_cnt = 0\n",
        "    temp_dims = [0]\n",
        "    for name, layer in model.named_modules():\n",
        "        if isinstance(layer, SparseConv) or isinstance(layer, SparseFc):\n",
        "            if isinstance(layer, SparseConv):\n",
        "                w = layer.conv.weight\n",
        "            elif isinstance(layer, SparseFc):\n",
        "                w = layer.fc.weight\n",
        "            temp_dims.append(w.numel())\n",
        "            prunable_weights_cnt += w.numel()\n",
        "\n",
        "    idx_list = [0]\n",
        "    for i in range(len(temp_dims)):\n",
        "        idx_list.append(temp_dims[i] + idx_list[i])\n",
        "\n",
        "    return prunable_weights_cnt, idx_list\n",
        "\n",
        "def calc_thresh(w, ratio):\n",
        "    w_sorted, _ = torch.sort(w)\n",
        "    m = (len(w_sorted)-1)*ratio\n",
        "    idx_floor, idx_ceil = int(np.floor(m)), int(np.ceil(m))\n",
        "    v1, v2 = w_sorted[idx_floor], w_sorted[idx_ceil]\n",
        "    thresh = v1 + (v2-v1)*(m-idx_floor)\n",
        "    return thresh.item()\n",
        "\n",
        "def get_global_thresh(model, device, st_batch, prunable_weights_cnt, idx_list):\n",
        "    i = 1\n",
        "    w_total = torch.empty(prunable_weights_cnt).to(device)\n",
        "    for name, layer in model.named_modules():\n",
        "        if isinstance(layer, SparseConv) or isinstance(layer, SparseFc):\n",
        "            if isinstance(layer, SparseConv):\n",
        "                w = layer.conv.weight.flatten().detach()\n",
        "            elif isinstance(layer, SparseFc):\n",
        "                w = layer.fc.weight.flatten().detach()\n",
        "\n",
        "            w_total[idx_list[i] : idx_list[i+1]] = w\n",
        "            i +=1\n",
        "\n",
        "    global_thresh = calc_thresh(torch.abs(w_total), st_batch)\n",
        "    return global_thresh\n",
        "\n",
        "def pruning_scheduler(final_rate, nbatches, ntotalsteps, t1):\n",
        "    kf = final_rate\n",
        "    t1 = t1*nbatches\n",
        "    t2 = int(np.floor(ntotalsteps*0.5))\n",
        "\n",
        "    t = np.arange(t1,t2)\n",
        "    k = np.hstack(( np.zeros(t1), ( kf - kf*(1-(t-t1)/(t2-t1))**3), kf*np.ones(ntotalsteps-t2) ))\n",
        "    return k\n",
        "\n",
        "def get_theta(final_rate):\n",
        "    if final_rate > 0.95:\n",
        "        theta = 0.5\n",
        "    else:\n",
        "        theta = 1.0\n",
        "    return theta\n",
        "\n",
        "\n",
        "class Pruner:\n",
        "    def __init__(self, model, device, final_rate, nbatches, epochs, pthres=0, t1=0):\n",
        "        theta = get_theta(final_rate)\n",
        "        self.ntotalsteps = nbatches * epochs\n",
        "        self.step_idx = 0\n",
        "\n",
        "        self.feather = Feather(gth=0.0, theta=theta)\n",
        "        self.device = device\n",
        "        self.t1 = t1\n",
        "\n",
        "        self.model = model\n",
        "\n",
        "        iter_sparsify(m=self.model, feather=self.feather, pthres=pthres)\n",
        "        # print(self.model)\n",
        "\n",
        "        prunable_weights_cnt, idx_list = get_prunable_weights_cnt(self.model)\n",
        "        self.prunable_weights_cnt = prunable_weights_cnt\n",
        "        self.idx_list = idx_list\n",
        "\n",
        "        pscheduler = pruning_scheduler(final_rate, nbatches, self.ntotalsteps, self.t1)\n",
        "        self.pscheduler = pscheduler\n",
        "\n",
        "    def update_thresh(self, end_of_batch=False):\n",
        "        idx = self.step_idx\n",
        "        if end_of_batch:\n",
        "            idx -=1\n",
        "        st_batch = self.pscheduler[idx]\n",
        "\n",
        "        new_gth = 0.0\n",
        "        if st_batch > 0:\n",
        "            new_gth = get_global_thresh(self.model, self.device, st_batch, self.prunable_weights_cnt, self.idx_list)\n",
        "\n",
        "        self.feather.gth = new_gth\n",
        "        if not end_of_batch:\n",
        "            self.step_idx += 1\n",
        "\n",
        "    def print_sparsity(self):\n",
        "        local_zeros_cnt = 0\n",
        "        for name, layer in resnet_model.named_modules():\n",
        "            if isinstance(layer, SparseConv) or isinstance(layer, SparseFc):\n",
        "                if isinstance(layer, SparseConv):\n",
        "                    w = layer.conv.weight\n",
        "                elif isinstance(layer, SparseFc):\n",
        "                    w = layer.fc.weight\n",
        "\n",
        "                th = pruner.feather.gth\n",
        "                nw = F.hardshrink(w, th)\n",
        "                tsparsity = (nw == 0).float().sum().item()\n",
        "\n",
        "                tnum = nw.numel()\n",
        "                print(f'{name}'.ljust(40), f'#w: {int(tnum)}'.ljust(11), f'| sparsity: {round(100.0 * tsparsity / tnum, 2)}%'.ljust(18))\n",
        "\n",
        "        return 100 * float(local_zeros_cnt) / float(self.prunable_weights_cnt)\n",
        "\n",
        "    def desparsify(self):\n",
        "        iter_desparsify(self.model, self.feather)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7da2779f",
      "metadata": {
        "id": "7da2779f"
      },
      "outputs": [],
      "source": [
        "data_type = hyperparameters['dataset']\n",
        "\n",
        "print(f'Data type: {data_type}')\n",
        "\n",
        "\n",
        "transform_train = transforms.Compose([\n",
        "    transforms.RandomCrop(size=32, padding=4),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.4914, 0.4822, 0.4465],\n",
        "                         std=[0.2023, 0.1994, 0.201]),\n",
        "])\n",
        "\n",
        "transform_val = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.4914, 0.4822, 0.4465],\n",
        "                         std=[0.2023, 0.1994, 0.201]),\n",
        "])\n",
        "\n",
        "\n",
        "if data_type == \"cifar10\":\n",
        "    train_dataset = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform_train)\n",
        "    test_dataset = datasets.CIFAR10(root='./data', train=False, download=True, transform=transform_val)\n",
        "elif data_type == 'cifar100':\n",
        "    train_dataset = datasets.CIFAR100(root='./data', train=True, download=True, transform=transform_train)\n",
        "    test_dataset = datasets.CIFAR100(root='./data', train=False, download=True, transform=transform_val)\n",
        "\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=hyperparameters['batch_size'], shuffle=True, num_workers=2)\n",
        "test_loader = DataLoader(test_dataset, batch_size=hyperparameters['batch_size'], shuffle=False, num_workers=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e0434edf",
      "metadata": {
        "id": "e0434edf"
      },
      "outputs": [],
      "source": [
        "model_type = hyperparameters['model_type']\n",
        "classes = 100 if data_type == 'cifar100' else 10\n",
        "\n",
        "print(f'Model: {model_type}')\n",
        "\n",
        "if model_type == 'rn20':\n",
        "    resnet_model = ResNet20(classes)\n",
        "    resnet_model.to(device)\n",
        "elif model_type == 'rn50':\n",
        "    resnet_model = ResNet(Bottleneck, [3, 4, 6, 3], num_classes=classes)\n",
        "    resnet_model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "300165e8",
      "metadata": {
        "id": "300165e8"
      },
      "outputs": [],
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(resnet_model.parameters(), lr=hyperparameters['lr'],\n",
        "                      momentum=hyperparameters['momentum'], weight_decay=hyperparameters['weight_decay'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1384987b",
      "metadata": {
        "id": "1384987b"
      },
      "outputs": [],
      "source": [
        "current_learning_rate = 0.1\n",
        "\n",
        "decay_type = hyperparameters['lr_decay']\n",
        "if decay_type == 'linear':\n",
        "    DECAY = 0.2\n",
        "    DECAY_EPOCHS = [60, 120, 160]\n",
        "elif decay_type == 'cosine':\n",
        "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, hyperparameters['T_max'], hyperparameters['lr_min'])\n",
        "\n",
        "print(f'LR schedule: {decay_type}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "66655472",
      "metadata": {
        "id": "66655472"
      },
      "outputs": [],
      "source": [
        "pruner = Pruner(resnet_model,\n",
        "                device,\n",
        "                final_rate=hyperparameters['final_rate'],\n",
        "                nbatches=hyperparameters['batch_size'],\n",
        "                epochs=hyperparameters['epochs'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c80223c8",
      "metadata": {
        "id": "c80223c8"
      },
      "outputs": [],
      "source": [
        "def train(model, train_loader, criterion, optimizer, epoch, log_file):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    pbar = tqdm(train_loader, desc=f\"Epoch {epoch+1}\")\n",
        "\n",
        "    for batch_idx, (inputs, targets) in enumerate(pbar):\n",
        "        pruner.update_thresh()\n",
        "\n",
        "        inputs, targets = inputs.to(device), targets.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, targets)\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "        _, predicted = outputs.max(1)\n",
        "        correct += predicted.eq(targets).sum().item()\n",
        "        total += targets.size(0)\n",
        "\n",
        "        pbar.set_postfix(loss=running_loss/(batch_idx+1), accuracy=100.0 * correct / total)\n",
        "\n",
        "    avg_loss = running_loss / len(train_loader)\n",
        "    accuracy = 100.0 * correct / total\n",
        "\n",
        "    sparsity = pruner.print_sparsity()\n",
        "    log_file.write(f'Epoch [{epoch+1}], Loss: {avg_loss:.4f}, Accuracy: {accuracy:.2f}%, Sparsity: {sparsity:.2f}%\\n')\n",
        "\n",
        "    pruner.update_thresh(end_of_batch=True)\n",
        "\n",
        "    return avg_loss, accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a5dad223",
      "metadata": {
        "id": "a5dad223"
      },
      "outputs": [],
      "source": [
        "def test(model, test_loader, criterion, log_file):\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    test_loss = 0.0\n",
        "\n",
        "    pbar = tqdm(test_loader, desc=\"Testing\")\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, targets in pbar:\n",
        "            inputs, targets = inputs.to(device), targets.to(device)\n",
        "\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, targets)\n",
        "            test_loss += loss.item()\n",
        "\n",
        "            _, predicted = outputs.max(1)\n",
        "            correct += predicted.eq(targets).sum().item()\n",
        "            total += targets.size(0)\n",
        "\n",
        "            pbar.set_postfix(loss=test_loss/(total + inputs.size(0)), accuracy=100.0 * correct / total)\n",
        "\n",
        "    avg_test_loss = test_loss / len(test_loader)\n",
        "    accuracy = 100.0 * correct / total\n",
        "    log_file.write(f'Test Loss: {avg_test_loss:.4f}, Accuracy: {accuracy:.2f}%\\n')\n",
        "\n",
        "    return avg_test_loss, accuracy\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "73f81f15",
      "metadata": {
        "id": "73f81f15"
      },
      "outputs": [],
      "source": [
        "hyperparameter_file = os.path.join('./', 'hyperparameters.txt')\n",
        "with open(hyperparameter_file, 'w') as f:\n",
        "    for key, value in hyperparameters.items():\n",
        "        f.write(f\"{key}: {value}\\n\")\n",
        "\n",
        "log_file_path = os.path.join('./', 'training_log.txt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "78402283",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "78402283"
      },
      "outputs": [],
      "source": [
        "with open(log_file_path, 'w') as log_file:\n",
        "    log_file.write(f\"Training started at {datetime.now()}\\n\")\n",
        "\n",
        "    best_accuracy = 0.0\n",
        "\n",
        "    for epoch in range(hyperparameters['epochs']):\n",
        "        train_loss, train_accuracy = train(pruner.model, train_loader, criterion, optimizer, epoch, log_file)\n",
        "        test_loss, test_accuracy = test(pruner.model, test_loader, criterion, log_file)\n",
        "\n",
        "        if test_accuracy > best_accuracy:\n",
        "            best_accuracy = test_accuracy\n",
        "            model_checkpoint_path = os.path.join('./', f\"best_model.pth\")\n",
        "            # pruner.desparsify()\n",
        "            torch.save(pruner.model.state_dict(), model_checkpoint_path)\n",
        "            print(f\"Saved best model at epoch {epoch+1} with accuracy: {best_accuracy:.2f}%\")\n",
        "\n",
        "        if decay_type == 'linear':\n",
        "            if epoch+1 in DECAY_EPOCHS:\n",
        "                current_learning_rate = current_learning_rate * DECAY\n",
        "                for param_group in optimizer.param_groups:\n",
        "                    param_group['lr'] = current_learning_rate\n",
        "                print(\"Current learning rate has decayed to %f\" %current_learning_rate)\n",
        "        elif decay_type == 'cosine':\n",
        "            scheduler.step()\n",
        "            curr_lr = scheduler.get_last_lr()[0]\n",
        "            print(f\"Current learning rate has decayed to {curr_lr:.6f}\")\n",
        "\n",
        "\n",
        "    log_file.write(f\"Training completed at {datetime.now()}\\n\")\n",
        "    log_file.write(f\"Best model accuracy: {best_accuracy:.2f}%\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "CNWJztJHzA4r",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "CNWJztJHzA4r"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ZVqcad60rGT7",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "ZVqcad60rGT7"
      },
      "outputs": [],
      "source": [
        "from torchvision import transforms, datasets\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "transform = transforms.Compose([transforms.ToTensor()])\n",
        "dataset = datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
        "loader = DataLoader(dataset, batch_size=20, shuffle=False)\n",
        "images, _ = next(iter(loader))  # [10, 3, 32, 32]\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6HiWmigLwdv0",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "6HiWmigLwdv0"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "uZ_m-DldrjfU",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "uZ_m-DldrjfU"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "def calculate_sparsity(tensor):\n",
        "    if tensor is None:\n",
        "        return 0.0, 0, 0\n",
        "    num_zeros = torch.sum(tensor == 0).item()\n",
        "    total_elements = tensor.numel()\n",
        "    return num_zeros / total_elements, num_zeros, total_elements\n",
        "\n",
        "state_dict = pruner.model.state_dict()\n",
        "\n",
        "if \"state_dict\" in state_dict:\n",
        "    state_dict = state_dict[\"state_dict\"]\n",
        "\n",
        "new_state_dict = {}\n",
        "for k, v in state_dict.items():\n",
        "    new_k = k.replace(\"module.\", \"\") if k.startswith(\"module.\") else k\n",
        "    new_state_dict[new_k] = v\n",
        "resnet_model.load_state_dict(new_state_dict, strict=False)\n",
        "\n",
        "total_zeros = 0\n",
        "total_params = 0\n",
        "\n",
        "for name, param in pruner.model.named_parameters():\n",
        "    if 'weight' in name and param.requires_grad:\n",
        "        sparsity, zeros, total = calculate_sparsity(param.data)\n",
        "        print(f\"{name:40s}: sparsity = {sparsity:.4f}\")\n",
        "        total_zeros += zeros\n",
        "        total_params += total\n",
        "\n",
        "for name, layer in resnet_model.named_modules():\n",
        "    if isinstance(layer, SparseConv) or isinstance(layer, SparseFc):\n",
        "        if isinstance(layer, SparseConv):\n",
        "            w = layer.conv.weight\n",
        "        elif isinstance(layer, SparseFc):\n",
        "            w = layer.fc.weight\n",
        "\n",
        "        th = pruner.feather.gth\n",
        "        nw = F.hardshrink(w, th)\n",
        "        tsparsity = (nw == 0).float().sum().item()\n",
        "\n",
        "        tnum = nw.numel()\n",
        "        print(f'{name}'.ljust(40), f'#w: {int(tnum)}'.ljust(11), f'| sparsity: {round(100.0 * tsparsity / tnum, 2)}%'.ljust(18))\n",
        "\n",
        "total_sparsity = total_zeros / total_params\n",
        "print(f\"\\nTotal model sparsity: {total_sparsity:.4f} ({total_zeros:,} zero weights out of {total_params:,})\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "OE9TsV_xxhsr",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "OE9TsV_xxhsr"
      },
      "outputs": [],
      "source": [
        "import torch.nn.functional as F\n",
        "\n",
        "def hard_prune_model_weights(model, threshold):\n",
        "    for name, layer in model.named_modules():\n",
        "        if isinstance(layer, SparseConv):\n",
        "            weight = layer.conv.weight.data\n",
        "            mask = weight.abs() < threshold\n",
        "            weight[mask] = 0.0\n",
        "            print(f\"[Pruned] {name} (SparseConv): Set {mask.sum().item()} weights to zero\")\n",
        "\n",
        "        elif isinstance(layer, SparseFc):\n",
        "            weight = layer.fc.weight.data\n",
        "            mask = weight.abs() < threshold\n",
        "            weight[mask] = 0.0\n",
        "            print(f\"[Pruned] {name} (SparseFc): Set {mask.sum().item()} weights to zero\")\n",
        "\n",
        "hard_prune_model_weights(resnet_model, pruner.feather.gth)\n",
        "torch.save(resnet_model.state_dict(), \"resnet_pruned.pth\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "X2Z_Q5erF4BO",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "X2Z_Q5erF4BO"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from collections import OrderedDict\n",
        "\n",
        "f_m = ResNet(Bottleneck, [3, 4, 6, 3], num_classes=100)\n",
        "\n",
        "source_params = list(resnet_model.state_dict().items())\n",
        "target_params = list(f_m.state_dict().items())\n",
        "\n",
        "assert len(source_params) == len(target_params), \"Mismatch in number of parameters\"\n",
        "\n",
        "new_state_dict = OrderedDict()\n",
        "\n",
        "for (t_name, _), (s_name, s_param) in zip(target_params, source_params):\n",
        "    new_state_dict[t_name] = s_param.clone()\n",
        "\n",
        "f_m.load_state_dict(new_state_dict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "IpcU740Wxkf5",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "IpcU740Wxkf5"
      },
      "outputs": [],
      "source": [
        "state_dict = f_m.state_dict()\n",
        "\n",
        "if \"state_dict\" in state_dict:\n",
        "    state_dict = state_dict[\"state_dict\"]\n",
        "\n",
        "new_state_dict = {}\n",
        "for k, v in state_dict.items():\n",
        "    new_k = k.replace(\"module.\", \"\") if k.startswith(\"module.\") else k\n",
        "    new_state_dict[new_k] = v\n",
        "f_m.load_state_dict(new_state_dict, strict=False)\n",
        "\n",
        "total_zeros = 0\n",
        "total_params = 0\n",
        "\n",
        "for name, param in f_m.named_parameters():\n",
        "    if 'weight' in name and param.requires_grad:\n",
        "        sparsity, zeros, total = calculate_sparsity(param.data)\n",
        "        print(f\"{name:40s}: sparsity = {sparsity:.4f}\")\n",
        "        total_zeros += zeros\n",
        "        total_params += total"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "hWmx3RJrE1tk",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "hWmx3RJrE1tk"
      },
      "outputs": [],
      "source": [
        "torch.save(f_m.state_dict(), './final_pruned_model.pth')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "v2RxmZoWxvya",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "v2RxmZoWxvya"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "transform_test = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5071, 0.4865, 0.4409), (0.2673, 0.2564, 0.2762)),  # CIFAR-100 mean & std\n",
        "])\n",
        "\n",
        "test_dataset = datasets.CIFAR100(root='./data', train=False, download=True, transform=transform_test)\n",
        "test_loader = DataLoader(test_dataset, batch_size=128, shuffle=False, num_workers=2)\n",
        "\n",
        "def evaluate(model, dataloader, criterion):\n",
        "    model.eval()\n",
        "    device = next(model.parameters()).device\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    total_loss = 0.0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, labels in dataloader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            total_loss += loss.item() * images.size(0)\n",
        "\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "            total += labels.size(0)\n",
        "\n",
        "    accuracy = 100.0 * correct / total\n",
        "    avg_loss = total_loss / total\n",
        "    return avg_loss, accuracy\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "test_loss, test_accuracy = evaluate(resnet_model, test_loader, criterion)\n",
        "print(f\"Test Accuracy: {test_accuracy:.2f}% | Test Loss: {test_loss:.4f}\")\n",
        "\n",
        "print(resnet_model)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ov2VpPb0Al0y",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "ov2VpPb0Al0y"
      },
      "outputs": [],
      "source": [
        "torch.save(resnet_model, \"pruned_full_model.pth\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "v5aC6SRAM6Xa",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "v5aC6SRAM6Xa"
      },
      "outputs": [],
      "source": [
        "pruner.desparsify()\n",
        "print(resnet_model)\n",
        "\n",
        "test_loss, test_accuracy = evaluate(resnet_model, test_loader, criterion)\n",
        "print(f\"Test Accuracy: {test_accuracy:.2f}% | Test Loss: {test_loss:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(pruner.feather.gth)\n",
        "torch.save(pruner.model.state_dict(), \"mymodel.pth\")"
      ],
      "metadata": {
        "id": "WGTc-SvgfHxZ"
      },
      "id": "WGTc-SvgfHxZ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "lEeJIgKvNjBx",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "lEeJIgKvNjBx"
      },
      "outputs": [],
      "source": [
        "torch.save(resnet_model.state_dict(), \"r1.pth\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}