{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1f7893a0",
      "metadata": {
        "id": "1f7893a0"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torchvision.transforms as transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets\n",
        "from resnet import ResNet20, ResNet, Bottleneck\n",
        "from datetime import datetime\n",
        "from tqdm.notebook import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3f8be9cc",
      "metadata": {
        "id": "3f8be9cc"
      },
      "outputs": [],
      "source": [
        "hyperparameters = {\n",
        "    'epochs': 100,\n",
        "    'lr': 0.1,\n",
        "    'lr_min': 1e-6,\n",
        "    'momentum': 0.9,\n",
        "    'weight_decay': 5e-4,\n",
        "    'batch_size': 128,\n",
        "    'sparsity_type': \"sandwich\",\n",
        "    'dataset': 'cifar100',\n",
        "    'model_type': 'rn50',\n",
        "    'lr_decay': \"cosine\",\n",
        "    'T_max': 100,\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d77c9b84",
      "metadata": {
        "id": "d77c9b84"
      },
      "outputs": [],
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "90adc31e",
      "metadata": {
        "id": "90adc31e"
      },
      "outputs": [],
      "source": [
        "data_type = hyperparameters['dataset']\n",
        "data_path = \"./\"\n",
        "print(f'Data type: {data_type}')\n",
        "\n",
        "\n",
        "transform_train = transforms.Compose([\n",
        "    transforms.RandomCrop(size=32, padding=4),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.4914, 0.4822, 0.4465],\n",
        "                         std=[0.2023, 0.1994, 0.201]),\n",
        "])\n",
        "\n",
        "transform_val = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.4914, 0.4822, 0.4465],\n",
        "                         std=[0.2023, 0.1994, 0.201]),\n",
        "])\n",
        "\n",
        "\n",
        "if data_type == \"cifar10\":\n",
        "    train_dataset = datasets.CIFAR10(root=data_path, train=True, download=True, transform=transform_train)\n",
        "    test_dataset = datasets.CIFAR10(root=data_path, train=False, download=True, transform=transform_val)\n",
        "elif data_type == 'cifar100':\n",
        "    train_dataset = datasets.CIFAR100(root=data_path, train=True, download=True, transform=transform_train)\n",
        "    test_dataset = datasets.CIFAR100(root=data_path, train=False, download=True, transform=transform_val)\n",
        "\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=hyperparameters['batch_size'], shuffle=True, num_workers=2)\n",
        "test_loader = DataLoader(test_dataset, batch_size=hyperparameters['batch_size'], shuffle=False, num_workers=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cca5b58b",
      "metadata": {
        "id": "cca5b58b"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class Pruner:\n",
        "    def __init__(self, model, N=10, M=100):\n",
        "        self.model = model\n",
        "        self.N = N\n",
        "        self.M = M\n",
        "\n",
        "    def apply_surprisal_sparsity(self):\n",
        "        for name, module in self.model.named_modules():\n",
        "            if isinstance(module, nn.Conv2d) and \"conv2\" in name:\n",
        "                weight = module.weight.data\n",
        "                N_filters, C, H, W = weight.shape\n",
        "                weight_flat = weight.view(N_filters, -1)\n",
        "\n",
        "                for i in range(N_filters):\n",
        "                    filter_w = weight_flat[i]\n",
        "                    original_len = filter_w.numel()\n",
        "\n",
        "                    pad_len = (self.M - original_len % self.M) % self.M\n",
        "                    if pad_len > 0:\n",
        "                        filter_w = F.pad(filter_w, (0, pad_len), mode='constant', value=0.0)\n",
        "\n",
        "                    grouped = filter_w.view(-1, self.M)\n",
        "                    abs_group = grouped.abs()\n",
        "                    group_sum = abs_group.sum(dim=1, keepdim=True) + 1e-8\n",
        "                    probs = abs_group / group_sum\n",
        "\n",
        "                    entropy = -probs * torch.log(probs + 1e-10)\n",
        "                    entropy_score = entropy\n",
        "\n",
        "                    topk = self.N if self.prune_high_entropy else (self.M - self.N)\n",
        "\n",
        "                    topk_indices = torch.topk(entropy_score, self.N, dim=1).indices\n",
        "\n",
        "                    mask = torch.zeros_like(grouped)\n",
        "                    mask.scatter_(1, topk_indices, 1.0 if self.prune_high_entropy else 0.0)\n",
        "                    grouped *= mask\n",
        "\n",
        "                    pruned_flat = grouped.view(-1)\n",
        "\n",
        "                    if pad_len > 0:\n",
        "                        pruned_flat = pruned_flat[:-pad_len]\n",
        "\n",
        "                    weight_flat[i] = pruned_flat\n",
        "\n",
        "                module.weight.data = weight_flat.view(N_filters, C, H, W)\n",
        "\n",
        "    def apply_nm_sparsity(self):\n",
        "        for name, module in self.model.named_modules():\n",
        "            if isinstance(module, nn.Conv2d) and (\"conv1\" in name):\n",
        "                weight = module.weight.data\n",
        "                orig_shape = weight.shape\n",
        "                flattened = weight.view(-1)\n",
        "\n",
        "                pad_len = (4 - flattened.numel() % 4) % 4\n",
        "                if pad_len > 0:\n",
        "                    flattened = F.pad(flattened, (0, pad_len))\n",
        "\n",
        "                grouped = flattened.view(-1, 4)\n",
        "                abs_vals = grouped.abs()\n",
        "\n",
        "                topk_vals, topk_idx = torch.topk(abs_vals, k=2, dim=1)\n",
        "                mask = torch.zeros_like(grouped)\n",
        "                mask.scatter_(1, topk_idx, 1.0)\n",
        "\n",
        "                sparse_grouped = grouped * mask\n",
        "                sparse_flat = sparse_grouped.view(-1)\n",
        "\n",
        "                if pad_len > 0:\n",
        "                    sparse_flat = sparse_flat[:-pad_len]\n",
        "\n",
        "                module.weight.data = sparse_flat.view(orig_shape)\n",
        "\n",
        "\n",
        "    def print_sparsity(self):\n",
        "        tot_params, tot_zeros = 0, 0\n",
        "        for name, module in self.model.named_modules():\n",
        "            if isinstance(module, nn.Conv2d):\n",
        "                weight = module.weight.data\n",
        "                n_params = weight.numel()\n",
        "                n_zeros = torch.sum(weight == 0).item()\n",
        "                tot_params += n_params\n",
        "                tot_zeros += n_zeros\n",
        "                print(f\"{name}: Total Params = {n_params}. Zero Params = {n_zeros}. Sparsity = {n_zeros / n_params:.2%}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "108d9ae1",
      "metadata": {
        "id": "108d9ae1"
      },
      "outputs": [],
      "source": [
        "def train(model, train_loader, criterion, optimizer, epoch, log_file):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    pbar = tqdm(train_loader, desc=f\"Epoch {epoch+1}\")\n",
        "\n",
        "    for batch_idx, (inputs, targets) in enumerate(pbar):\n",
        "        inputs, targets = inputs.to(device), targets.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, targets)\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "        _, predicted = outputs.max(1)\n",
        "        correct += predicted.eq(targets).sum().item()\n",
        "        total += targets.size(0)\n",
        "\n",
        "        pbar.set_postfix(loss=running_loss/(batch_idx+1), accuracy=100.0 * correct / total)\n",
        "\n",
        "    avg_loss = running_loss / len(train_loader)\n",
        "    accuracy = 100.0 * correct / total\n",
        "    log_file.write(f'Epoch [{epoch+1}], Loss: {avg_loss:.4f}, Accuracy: {accuracy:.2f}%\\n')\n",
        "    sys.stdout.flush()\n",
        "\n",
        "    return avg_loss, accuracy\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fc457b71",
      "metadata": {
        "id": "fc457b71"
      },
      "outputs": [],
      "source": [
        "def test(model, test_loader, criterion, log_file):\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    test_loss = 0.0\n",
        "\n",
        "    pbar = tqdm(test_loader, desc=\"Testing\")\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, targets in pbar:\n",
        "            inputs, targets = inputs.to(device), targets.to(device)\n",
        "\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, targets)\n",
        "            test_loss += loss.item()\n",
        "\n",
        "            _, predicted = outputs.max(1)\n",
        "            correct += predicted.eq(targets).sum().item()\n",
        "            total += targets.size(0)\n",
        "\n",
        "            pbar.set_postfix(loss=test_loss/(total + inputs.size(0)), accuracy=100.0 * correct / total)\n",
        "\n",
        "    avg_test_loss = test_loss / len(test_loader)\n",
        "    accuracy = 100.0 * correct / total\n",
        "    log_file.write(f'Test Loss: {avg_test_loss:.4f}, Accuracy: {accuracy:.2f}%\\n')\n",
        "    sys.stdout.flush()\n",
        "\n",
        "    return avg_test_loss, accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "47261fcb",
      "metadata": {
        "id": "47261fcb"
      },
      "outputs": [],
      "source": [
        "model_type = hyperparameters['model_type']\n",
        "classes = 100 if data_type == 'cifar100' else 10\n",
        "\n",
        "if model_type == 'rn20':\n",
        "    resnet_model = ResNet20(classes)\n",
        "    resnet_model.to(device)\n",
        "elif model_type == 'rn50':\n",
        "    resnet_model = ResNet(Bottleneck, [3, 4, 6, 3], num_classes=classes)\n",
        "    resnet_model.to(device)\n",
        "\n",
        "resnet_model.load_state_dict(torch.load(\"./base.pth\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "425a4c59",
      "metadata": {
        "id": "425a4c59"
      },
      "outputs": [],
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(resnet_model.parameters(), lr=hyperparameters['lr'],\n",
        "                      momentum=hyperparameters['momentum'], weight_decay=hyperparameters['weight_decay'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0f6884c6",
      "metadata": {
        "id": "0f6884c6"
      },
      "outputs": [],
      "source": [
        "current_learning_rate = 0.1\n",
        "\n",
        "decay_type = hyperparameters['lr_decay']\n",
        "if decay_type == 'linear':\n",
        "    DECAY = 0.2\n",
        "    DECAY_EPOCHS = [60, 120, 160]\n",
        "elif decay_type == 'cosine':\n",
        "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, hyperparameters['T_max'], hyperparameters['lr_min'])\n",
        "\n",
        "print(f'LR schedule: {decay_type}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "17d23b22",
      "metadata": {
        "id": "17d23b22"
      },
      "outputs": [],
      "source": [
        "hyperparameter_file = os.path.join(\"./\", 'hyperparameters.txt')\n",
        "with open(hyperparameter_file, 'w') as f:\n",
        "    for key, value in hyperparameters.items():\n",
        "        f.write(f\"{key}: {value}\\n\")\n",
        "\n",
        "log_file_path = os.path.join(\"./\", 'training_log.txt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e5b9f4a8",
      "metadata": {
        "id": "e5b9f4a8"
      },
      "outputs": [],
      "source": [
        "pruner = Pruner(resnet_model, N=10, M=100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8b8e35c4",
      "metadata": {
        "id": "8b8e35c4"
      },
      "outputs": [],
      "source": [
        "with open(log_file_path, 'w') as log_file:\n",
        "    log_file.write(f\"Training started at {datetime.now()}\\n\")\n",
        "\n",
        "    best_accuracy = 0.0\n",
        "\n",
        "    for epoch in range(hyperparameters['epochs']):\n",
        "        train_loss, train_accuracy = train(resnet_model, train_loader, criterion, optimizer, epoch, log_file)\n",
        "\n",
        "        pruner.apply_surprisal_sparsity()\n",
        "        pruner.apply_nm_sparsity()\n",
        "\n",
        "        test_loss, test_accuracy = test(resnet_model, test_loader, criterion, log_file)\n",
        "\n",
        "        pruner.print_sparsity()\n",
        "\n",
        "        if test_accuracy > best_accuracy:\n",
        "            best_accuracy = test_accuracy\n",
        "            model_checkpoint_path = os.path.join(\"./\", f\"best_model.pth\")\n",
        "            torch.save(resnet_model.state_dict(), model_checkpoint_path)\n",
        "            print(f\"Saved best model at epoch {epoch+1} with accuracy: {best_accuracy:.2f}%\")\n",
        "\n",
        "        if decay_type == 'linear':\n",
        "            if epoch+1 in DECAY_EPOCHS:\n",
        "                current_learning_rate = current_learning_rate * DECAY\n",
        "                for param_group in optimizer.param_groups:\n",
        "                    param_group['lr'] = current_learning_rate\n",
        "                print(\"Current learning rate has decayed to %f\" %current_learning_rate)\n",
        "        elif decay_type == 'cosine':\n",
        "            scheduler.step()\n",
        "            curr_lr = scheduler.get_last_lr()[0]\n",
        "            print(f\"Current learning rate has decayed to {curr_lr:.6f}\")\n",
        "\n",
        "\n",
        "    log_file.write(f\"Training completed at {datetime.now()}\\n\")\n",
        "    log_file.write(f\"Best model accuracy: {best_accuracy:.2f}%\\n\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c2827570",
      "metadata": {
        "id": "c2827570"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}