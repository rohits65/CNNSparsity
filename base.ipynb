{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8ceac3a4",
      "metadata": {
        "id": "8ceac3a4"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets\n",
        "from resnet import ResNet20, ResNet, Bottleneck\n",
        "from datetime import datetime\n",
        "from tqdm.notebook import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cc00d111",
      "metadata": {
        "id": "cc00d111"
      },
      "outputs": [],
      "source": [
        "hyperparameters = {\n",
        "    'epochs': 300,\n",
        "    'lr': 0.1,\n",
        "    'lr_min': 1e-6,\n",
        "    'momentum': 0.9,\n",
        "    'weight_decay': 5e-4,\n",
        "    'batch_size': 128,\n",
        "    'sparsity_type': \"base\",\n",
        "    'dataset': 'cifar100',\n",
        "    'model_type': 'rn50',\n",
        "    'lr_decay': \"cosine\",\n",
        "    'T_max': 280,\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2aaf47af",
      "metadata": {
        "id": "2aaf47af"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "86020027",
      "metadata": {
        "id": "86020027"
      },
      "outputs": [],
      "source": [
        "data_type = hyperparameters['dataset']\n",
        "data_path = \"./\"\n",
        "\n",
        "print(f'Data type: {data_type}')\n",
        "\n",
        "\n",
        "transform_train = transforms.Compose([\n",
        "    transforms.RandomCrop(size=32, padding=4),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.4914, 0.4822, 0.4465],\n",
        "                         std=[0.2023, 0.1994, 0.201]),\n",
        "])\n",
        "\n",
        "transform_val = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.4914, 0.4822, 0.4465],\n",
        "                         std=[0.2023, 0.1994, 0.201]),\n",
        "])\n",
        "\n",
        "\n",
        "if data_type == \"cifar10\":\n",
        "    train_dataset = datasets.CIFAR10(root=data_path, train=True, download=True, transform=transform_train)\n",
        "    test_dataset = datasets.CIFAR10(root=data_path, train=False, download=True, transform=transform_val)\n",
        "elif data_type == 'cifar100':\n",
        "    train_dataset = datasets.CIFAR100(root=data_path, train=True, download=True, transform=transform_train)\n",
        "    test_dataset = datasets.CIFAR100(root=data_path, train=False, download=True, transform=transform_val)\n",
        "\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=hyperparameters['batch_size'], shuffle=True, num_workers=2)\n",
        "test_loader = DataLoader(test_dataset, batch_size=hyperparameters['batch_size'], shuffle=False, num_workers=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9f7fdfbf",
      "metadata": {
        "id": "9f7fdfbf"
      },
      "outputs": [],
      "source": [
        "def train(model, train_loader, criterion, optimizer, epoch, log_file):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    pbar = tqdm(train_loader, desc=f\"Epoch {epoch+1}\")\n",
        "\n",
        "    for batch_idx, (inputs, targets) in enumerate(pbar):\n",
        "        inputs, targets = inputs.to(device), targets.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, targets)\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "        _, predicted = outputs.max(1)\n",
        "        correct += predicted.eq(targets).sum().item()\n",
        "        total += targets.size(0)\n",
        "\n",
        "        pbar.set_postfix(loss=running_loss/(batch_idx+1), accuracy=100.0 * correct / total)\n",
        "\n",
        "    avg_loss = running_loss / len(train_loader)\n",
        "    accuracy = 100.0 * correct / total\n",
        "    log_file.write(f'Epoch [{epoch+1}], Loss: {avg_loss:.4f}, Accuracy: {accuracy:.2f}%\\n')\n",
        "\n",
        "    return avg_loss, accuracy\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d2276c36",
      "metadata": {
        "id": "d2276c36"
      },
      "outputs": [],
      "source": [
        "def test(model, test_loader, criterion, log_file):\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    test_loss = 0.0\n",
        "\n",
        "    pbar = tqdm(test_loader, desc=\"Testing\")\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, targets in pbar:\n",
        "            inputs, targets = inputs.to(device), targets.to(device)\n",
        "\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, targets)\n",
        "            test_loss += loss.item()\n",
        "\n",
        "            _, predicted = outputs.max(1)\n",
        "            correct += predicted.eq(targets).sum().item()\n",
        "            total += targets.size(0)\n",
        "\n",
        "            pbar.set_postfix(loss=test_loss/(total + inputs.size(0)), accuracy=100.0 * correct / total)\n",
        "\n",
        "    avg_test_loss = test_loss / len(test_loader)\n",
        "    accuracy = 100.0 * correct / total\n",
        "    log_file.write(f'Test Loss: {avg_test_loss:.4f}, Accuracy: {accuracy:.2f}%\\n')\n",
        "\n",
        "    return avg_test_loss, accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "70d27d17",
      "metadata": {
        "id": "70d27d17"
      },
      "outputs": [],
      "source": [
        "model_type = hyperparameters['model_type']\n",
        "classes = 100 if data_type == 'cifar100' else 10\n",
        "\n",
        "if model_type == 'rn20':\n",
        "    resnet_model = ResNet20(classes)\n",
        "    resnet_model.to(device)\n",
        "elif model_type == 'rn50':\n",
        "    resnet_model = ResNet(Bottleneck, [3, 4, 6, 3], num_classes=classes)\n",
        "    resnet_model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b83829f4",
      "metadata": {
        "id": "b83829f4"
      },
      "outputs": [],
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(resnet_model.parameters(), lr=hyperparameters['lr'],\n",
        "                      momentum=hyperparameters['momentum'], weight_decay=hyperparameters['weight_decay'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ce655306",
      "metadata": {
        "id": "ce655306"
      },
      "outputs": [],
      "source": [
        "current_learning_rate = 0.1\n",
        "\n",
        "decay_type = hyperparameters['lr_decay']\n",
        "if decay_type == 'linear':\n",
        "    DECAY = 0.2\n",
        "    DECAY_EPOCHS = [60, 120, 160]\n",
        "elif decay_type == 'cosine':\n",
        "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, hyperparameters['T_max'], hyperparameters['lr_min'])\n",
        "\n",
        "print(f'LR schedule: {decay_type}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b2a0ff77",
      "metadata": {
        "id": "b2a0ff77"
      },
      "outputs": [],
      "source": [
        "decay_type"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "231f1887",
      "metadata": {
        "id": "231f1887"
      },
      "outputs": [],
      "source": [
        "hyperparameter_file = os.path.join(\"./\", 'hyperparameters.txt')\n",
        "with open(hyperparameter_file, 'w') as f:\n",
        "    for key, value in hyperparameters.items():\n",
        "        f.write(f\"{key}: {value}\\n\")\n",
        "\n",
        "log_file_path = os.path.join(\"./\", 'training_log.txt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5067f2cb",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "5067f2cb"
      },
      "outputs": [],
      "source": [
        "with open(log_file_path, 'w') as log_file:\n",
        "    log_file.write(f\"Training started at {datetime.now()}\\n\")\n",
        "\n",
        "    best_accuracy = 0.0\n",
        "\n",
        "    for epoch in range(hyperparameters['epochs']):\n",
        "        train_loss, train_accuracy = train(resnet_model, train_loader, criterion, optimizer, epoch, log_file)\n",
        "        test_loss, test_accuracy = test(resnet_model, test_loader, criterion, log_file)\n",
        "\n",
        "        if test_accuracy > best_accuracy:\n",
        "            best_accuracy = test_accuracy\n",
        "            model_checkpoint_path = os.path.join(\"./\", f\"best_model.pth\")\n",
        "            torch.save(resnet_model.state_dict(), model_checkpoint_path)\n",
        "            print(f\"Saved best model at epoch {epoch+1} with accuracy: {best_accuracy:.2f}%\")\n",
        "\n",
        "        if decay_type == 'linear':\n",
        "            if epoch+1 in DECAY_EPOCHS:\n",
        "                current_learning_rate = current_learning_rate * DECAY\n",
        "                for param_group in optimizer.param_groups:\n",
        "                    param_group['lr'] = current_learning_rate\n",
        "                print(\"Current learning rate has decayed to %f\" %current_learning_rate)\n",
        "        elif decay_type == 'cosine':\n",
        "            scheduler.step()\n",
        "            curr_lr = scheduler.get_last_lr()[0]\n",
        "            print(f\"Current learning rate has decayed to {curr_lr:.6f}\")\n",
        "\n",
        "\n",
        "    log_file.write(f\"Training completed at {datetime.now()}\\n\")\n",
        "    log_file.write(f\"Best model accuracy: {best_accuracy:.2f}%\\n\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f3b85f09",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "f3b85f09"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}