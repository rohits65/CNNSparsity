{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1f7893a0",
      "metadata": {
        "id": "1f7893a0"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torchvision.transforms as transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets\n",
        "from resnet import ResNet20, ResNet, Bottleneck\n",
        "from datetime import datetime\n",
        "from tqdm.notebook import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3f8be9cc",
      "metadata": {
        "id": "3f8be9cc"
      },
      "outputs": [],
      "source": [
        "hyperparameters = {\n",
        "    'epochs': 100,\n",
        "    'lr': 0.1,\n",
        "    'lr_min': 1e-6,\n",
        "    'momentum': 0.9,\n",
        "    'weight_decay': 5e-4,\n",
        "    'batch_size': 128,\n",
        "    'sparsity_type': \"new_nm\",\n",
        "    'dataset': 'cifar100',\n",
        "    'model_type': 'rn50',\n",
        "    'lr_decay': \"cosine\",\n",
        "    'T_max': 100,\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d77c9b84",
      "metadata": {
        "id": "d77c9b84"
      },
      "outputs": [],
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "90adc31e",
      "metadata": {
        "id": "90adc31e"
      },
      "outputs": [],
      "source": [
        "data_type = hyperparameters['dataset']\n",
        "data_path = \"./\"\n",
        "print(f'Data type: {data_type}')\n",
        "\n",
        "\n",
        "transform_train = transforms.Compose([\n",
        "    transforms.RandomCrop(size=32, padding=4),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.4914, 0.4822, 0.4465],\n",
        "                         std=[0.2023, 0.1994, 0.201]),\n",
        "])\n",
        "\n",
        "transform_val = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.4914, 0.4822, 0.4465],\n",
        "                         std=[0.2023, 0.1994, 0.201]),\n",
        "])\n",
        "\n",
        "\n",
        "if data_type == \"cifar10\":\n",
        "    train_dataset = datasets.CIFAR10(root=data_path, train=True, download=True, transform=transform_train)\n",
        "    test_dataset = datasets.CIFAR10(root=data_path, train=False, download=True, transform=transform_val)\n",
        "elif data_type == 'cifar100':\n",
        "    train_dataset = datasets.CIFAR100(root=data_path, train=True, download=True, transform=transform_train)\n",
        "    test_dataset = datasets.CIFAR100(root=data_path, train=False, download=True, transform=transform_val)\n",
        "\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=hyperparameters['batch_size'], shuffle=True, num_workers=2)\n",
        "test_loader = DataLoader(test_dataset, batch_size=hyperparameters['batch_size'], shuffle=False, num_workers=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cca5b58b",
      "metadata": {
        "id": "cca5b58b"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class Pruner:\n",
        "    def __init__(self, model, sparsity_ratio=0.9):\n",
        "        self.model = model\n",
        "        self.sparsity_ratio = sparsity_ratio\n",
        "\n",
        "    # Prune based on magnitude\n",
        "    def apply_magnitude_pruning(self):\n",
        "        for name, module in self.model.named_modules():\n",
        "            if isinstance(module, nn.Conv2d) and \"conv2\" in name:\n",
        "                weight = module.weight.data\n",
        "                flat_weights = weight.view(-1).abs()\n",
        "                k = int(flat_weights.numel() * self.sparsity_ratio)\n",
        "\n",
        "                if k == 0:\n",
        "                    continue\n",
        "\n",
        "                threshold = torch.topk(flat_weights, k, largest=False).values.max()\n",
        "                mask = weight.abs() > threshold\n",
        "                weight *= mask\n",
        "\n",
        "                print(f\"Applied magnitude pruning on {name}, zeroed {k} smallest weights\")\n",
        "\n",
        "    def print_sparsity(self):\n",
        "        tot_params, tot_zeros = 0, 0\n",
        "        for name, module in self.model.named_modules():\n",
        "            if isinstance(module, nn.Conv2d):\n",
        "                weight = module.weight.data\n",
        "                n_params = weight.numel()\n",
        "                n_zeros = torch.sum(weight == 0).item()\n",
        "                tot_params += n_params\n",
        "                tot_zeros += n_zeros\n",
        "                print(f\"{name}: Total Params = {n_params}. Zero Params = {n_zeros}. Sparsity = {n_zeros / n_params:.2%}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "108d9ae1",
      "metadata": {
        "id": "108d9ae1"
      },
      "outputs": [],
      "source": [
        "def train(model, train_loader, criterion, optimizer, epoch, log_file):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    pbar = tqdm(train_loader, desc=f\"Epoch {epoch+1}\")\n",
        "\n",
        "    for batch_idx, (inputs, targets) in enumerate(pbar):\n",
        "        inputs, targets = inputs.to(device), targets.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, targets)\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "        _, predicted = outputs.max(1)\n",
        "        correct += predicted.eq(targets).sum().item()\n",
        "        total += targets.size(0)\n",
        "\n",
        "        pbar.set_postfix(loss=running_loss/(batch_idx+1), accuracy=100.0 * correct / total)\n",
        "\n",
        "    avg_loss = running_loss / len(train_loader)\n",
        "    accuracy = 100.0 * correct / total\n",
        "    log_file.write(f'Epoch [{epoch+1}], Loss: {avg_loss:.4f}, Accuracy: {accuracy:.2f}%\\n')\n",
        "    sys.stdout.flush()\n",
        "\n",
        "    return avg_loss, accuracy\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fc457b71",
      "metadata": {
        "id": "fc457b71"
      },
      "outputs": [],
      "source": [
        "def test(model, test_loader, criterion, log_file):\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    test_loss = 0.0\n",
        "\n",
        "    pbar = tqdm(test_loader, desc=\"Testing\")\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, targets in pbar:\n",
        "            inputs, targets = inputs.to(device), targets.to(device)\n",
        "\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, targets)\n",
        "            test_loss += loss.item()\n",
        "\n",
        "            _, predicted = outputs.max(1)\n",
        "            correct += predicted.eq(targets).sum().item()\n",
        "            total += targets.size(0)\n",
        "\n",
        "            pbar.set_postfix(loss=test_loss/(total + inputs.size(0)), accuracy=100.0 * correct / total)\n",
        "\n",
        "    avg_test_loss = test_loss / len(test_loader)\n",
        "    accuracy = 100.0 * correct / total\n",
        "    log_file.write(f'Test Loss: {avg_test_loss:.4f}, Accuracy: {accuracy:.2f}%\\n')\n",
        "    sys.stdout.flush()\n",
        "\n",
        "    return avg_test_loss, accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "47261fcb",
      "metadata": {
        "id": "47261fcb"
      },
      "outputs": [],
      "source": [
        "model_type = hyperparameters['model_type']\n",
        "classes = 100 if data_type == 'cifar100' else 10\n",
        "\n",
        "if model_type == 'rn20':\n",
        "    resnet_model = ResNet20(classes)\n",
        "    resnet_model.to(device)\n",
        "elif model_type == 'rn50':\n",
        "    resnet_model = ResNet(Bottleneck, [3, 4, 6, 3], num_classes=classes)\n",
        "    resnet_model.to(device)\n",
        "\n",
        "resnet_model.load_state_dict(torch.load(\"./base.pth\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "425a4c59",
      "metadata": {
        "id": "425a4c59"
      },
      "outputs": [],
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(resnet_model.parameters(), lr=hyperparameters['lr'],\n",
        "                      momentum=hyperparameters['momentum'], weight_decay=hyperparameters['weight_decay'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0f6884c6",
      "metadata": {
        "id": "0f6884c6"
      },
      "outputs": [],
      "source": [
        "current_learning_rate = 0.1\n",
        "\n",
        "decay_type = hyperparameters['lr_decay']\n",
        "if decay_type == 'linear':\n",
        "    DECAY = 0.2\n",
        "    DECAY_EPOCHS = [60, 120, 160]\n",
        "elif decay_type == 'cosine':\n",
        "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, hyperparameters['T_max'], hyperparameters['lr_min'])\n",
        "\n",
        "print(f'LR schedule: {decay_type}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "17d23b22",
      "metadata": {
        "id": "17d23b22"
      },
      "outputs": [],
      "source": [
        "hyperparameter_file = os.path.join(\"./\", 'hyperparameters.txt')\n",
        "with open(hyperparameter_file, 'w') as f:\n",
        "    for key, value in hyperparameters.items():\n",
        "        f.write(f\"{key}: {value}\\n\")\n",
        "\n",
        "log_file_path = os.path.join(\"./\", 'training_log.txt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e5b9f4a8",
      "metadata": {
        "id": "e5b9f4a8"
      },
      "outputs": [],
      "source": [
        "pruner = Pruner(resnet_model, sparsity_ratio=0.9)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8b8e35c4",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "8b8e35c4"
      },
      "outputs": [],
      "source": [
        "with open(log_file_path, 'w') as log_file:\n",
        "    log_file.write(f\"Training started at {datetime.now()}\\n\")\n",
        "\n",
        "    best_accuracy = 0.0\n",
        "\n",
        "    for epoch in range(hyperparameters['epochs']):\n",
        "        train_loss, train_accuracy = train(resnet_model, train_loader, criterion, optimizer, epoch, log_file)\n",
        "\n",
        "        # Enfornce sparsity pruning after each epoch\n",
        "        pruner.apply_magnitude_pruning()\n",
        "        pruner.print_sparsity()\n",
        "\n",
        "        test_loss, test_accuracy = test(resnet_model, test_loader, criterion, log_file)\n",
        "\n",
        "        pruner.print_sparsity()\n",
        "\n",
        "        if test_accuracy > best_accuracy:\n",
        "            best_accuracy = test_accuracy\n",
        "            model_checkpoint_path = os.path.join(\"./\", f\"best_model.pth\")\n",
        "            torch.save(resnet_model.state_dict(), model_checkpoint_path)\n",
        "            print(f\"Saved best model at epoch {epoch+1} with accuracy: {best_accuracy:.2f}%\")\n",
        "\n",
        "        if decay_type == 'linear':\n",
        "            if epoch+1 in DECAY_EPOCHS:\n",
        "                current_learning_rate = current_learning_rate * DECAY\n",
        "                for param_group in optimizer.param_groups:\n",
        "                    param_group['lr'] = current_learning_rate\n",
        "                print(\"Current learning rate has decayed to %f\" %current_learning_rate)\n",
        "        elif decay_type == 'cosine':\n",
        "            scheduler.step()\n",
        "            curr_lr = scheduler.get_last_lr()[0]\n",
        "            print(f\"Current learning rate has decayed to {curr_lr:.6f}\")\n",
        "\n",
        "\n",
        "    log_file.write(f\"Training completed at {datetime.now()}\\n\")\n",
        "    log_file.write(f\"Best model accuracy: {best_accuracy:.2f}%\\n\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c2827570",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "c2827570"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
